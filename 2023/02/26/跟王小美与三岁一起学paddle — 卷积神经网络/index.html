<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>跟着王小美和三岁一起学paddle(4)--卷积神经网络 | Flose's Blog</title><meta name="author" content="Flose"><meta name="copyright" content="Flose"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="跟王小美与三岁一起学paddle — 卷积神经网络篇！简单有趣带你深度学习 跟王小美与三岁一起学paddle 第四讲  致读者 在看这个notebook的你，对没错就是你 关注王小美喵，点个star⭐谢谢喵 注:本项目部分图片为自制，非授权请勿私自使用   王小美:  三岁老师，接下来是不是就要教我目标检测了呀？我已经准备好打穿csgo了 ٩(◕‿◕｡)۶  三岁:  可以是可以，但是千万别把号玩">
<meta property="og:type" content="article">
<meta property="og:title" content="跟着王小美和三岁一起学paddle(4)--卷积神经网络">
<meta property="og:url" content="https://flose.cn/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="Flose&#39;s Blog">
<meta property="og:description" content="跟王小美与三岁一起学paddle — 卷积神经网络篇！简单有趣带你深度学习 跟王小美与三岁一起学paddle 第四讲  致读者 在看这个notebook的你，对没错就是你 关注王小美喵，点个star⭐谢谢喵 注:本项目部分图片为自制，非授权请勿私自使用   王小美:  三岁老师，接下来是不是就要教我目标检测了呀？我已经准备好打穿csgo了 ٩(◕‿◕｡)۶  三岁:  可以是可以，但是千万别把号玩">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ai-studio-static-online.cdn.bcebos.com/c40042ec75d5412da45370abe110559a5fc38c887cb24b2f9010409f4523d918">
<meta property="article:published_time" content="2023-02-26T12:54:01.000Z">
<meta property="article:modified_time" content="2023-02-26T13:13:46.671Z">
<meta property="article:author" content="Flose">
<meta property="article:tag" content="cs">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ai-studio-static-online.cdn.bcebos.com/c40042ec75d5412da45370abe110559a5fc38c887cb24b2f9010409f4523d918"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://flose.cn/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '跟着王小美和三岁一起学paddle(4)--卷积神经网络',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-02-26 21:13:46'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/myStyle.css"><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.328888.xyz/2023/02/26/ESj8a.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://ai-studio-static-online.cdn.bcebos.com/c40042ec75d5412da45370abe110559a5fc38c887cb24b2f9010409f4523d918')"><nav id="nav"><span id="blog-info"><a href="/" title="Flose's Blog"><span class="site-name">Flose's Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">跟着王小美和三岁一起学paddle(4)--卷积神经网络</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-26T12:54:01.000Z" title="发表于 2023-02-26 20:54:01">2023-02-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-26T13:13:46.671Z" title="更新于 2023-02-26 21:13:46">2023-02-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="跟着王小美和三岁一起学paddle(4)--卷积神经网络"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="跟王小美与三岁一起学paddle-—-卷积神经网络篇！"><a href="#跟王小美与三岁一起学paddle-—-卷积神经网络篇！" class="headerlink" title="跟王小美与三岁一起学paddle — 卷积神经网络篇！"></a>跟王小美与三岁一起学paddle — 卷积神经网络篇！</h1><p>简单有趣带你深度学习</p>
<p>跟王小美与三岁一起学paddle 第四讲</p>
<blockquote>
<p>致读者</p>
<p>在看这个notebook的你，对没错就是你</p>
<p>关注王小美喵，点个star⭐谢谢喵</p>
<p>注:本项目部分图片为自制，非授权请勿私自使用</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/c40042ec75d5412da45370abe110559a5fc38c887cb24b2f9010409f4523d918"></p>
<table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>三岁老师，接下来是不是就要教我目标检测了呀？我已经准备好打穿csgo了 ٩(◕‿◕｡)۶ </p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>可以是可以，但是千万别把号玩封了啊，那我们就马上来打开新大门—-卷积神经网络</p>
<p>首先我们要从卷积学起来哦！(～o￣3￣)～</p>
<blockquote>
<h1 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h1><p>卷积运算是指从图像的左上角开始，开一个与模板同样大小的活动窗口，窗口图像与模板像元对应起来相乘再相加，并用计算结果代替窗口中心的像元亮度值。然后，活动窗口</p>
<p>向右移动一列，并作同样的运算。以此类推，从左到右、从上到下，即可得到一幅新图像。</p>
<p>我们也可以把卷积运算称之为滤波</p>
</blockquote>
<table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>为什么要对图片进行卷积运算呢？｡◕ᴗ◕｡</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>对于我们之前学的神经网络来说</p>
<p>一张图片所具有的信息量是非常大的，会有非常多的特征</p>
<p>假设我们用一台1200w像素的手机拍摄图片将他传入单隐藏层的神经网络就需要14G的显存，何况我们还要多层呢？</p>
<p>所以我们必须对他进行处理，提取重要信息</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/63aafb848ff74e3c9f86addf954feffb4b836520265741a28773a7537f3e7558"></p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<blockquote>
<p>对图像滤波要遵从两个原则</p>
<p>1.平移不变性</p>
<p>你找一个物品，不能受他位置的因素影响</p>
<p>2.局部性</p>
<p>你找一个物品，只需要在局部空间寻找</p>
<p>人们为了满足以上原则，使用了卷积</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/b41d720b5f464120b0bb22c2a308daf2df9aa528999b4437b8f7b5d864dd376f"></p>
<blockquote>
<h1 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h1><p>将输入和卷积核进行交叉相关再加上偏置进行输出的层(对输入进行卷积运算的层)</p>
<p>让我们来手动进行一次卷积吧！░ ∗ ◕ ں ◕ ∗ ░(下面这个例子我的偏置为0) </p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/2e1225d8fc3c4d2e81071f933e6d6313030a7feb0e6940508aa37d37c09f4e8c"></p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/b5445b0cf2484d7fac0a1005a3d78119d782a92055ef4b6db2487d48bc1d0dc4"></p>
</blockquote>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>在上图中，卷积核(Kernel)类似于线性回归的权重(W)</p>
<table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>我对自己做了个卷积运算，大家快来看看吧！(o°ω°o)</p>
<p>不同的卷积核可以带来不同的效果哦，自己动手试试看吧</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Fafa-DL/Image-Augmentation">刚学习的小白可以使用啥都生大佬的图像增强工具</a></p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/2bdbd756f33e446db6769f53b20a03759329b19d1f6946acb28d8139f3ac34f3"></p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>假设原图像的高为H 宽为W</p>
<p>卷积核的高为Kh，宽为Kw</p>
<p>当我们对图像做卷积的时候，我们发现输出图像的高是(H-Kh+1)，宽是(W-Kw+1)</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/a18cd1427d154f65b7ed286369a20356a355a054ee9f49dc8fc225f370f8ee06"></p>
<p>我们会发现，通过卷积输出的图像是越来越小的，并且如果卷积核越大，输出的图像就越小，如果我们输入的图像比较小的时候这就不利于我们搭建多层网络了。</p>
<p>那么我们要如何对输入图像做处理呢？</p>
<table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>无敌的王小美出现了，并说了一句：把输入图像变大就行了。 o(&gt;ω&lt;)o</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<blockquote>
<h1 id="填充-padding"><a href="#填充-padding" class="headerlink" title="填充(padding)"></a>填充(padding)</h1><p>是的，在输入图像周围填充空白像素，这个操作我们叫做padding(填充)</p>
<p>假设我们填充Pw，Ph</p>
<p>那么输出图像的长是(W-Kw+Pw+1) 宽是(H-Kh+Ph+1)</p>
<p>当Pw = Kw-1， Ph = Kh-1 输出图像大小就与输入图像大小一样了</p>
<p> 当Kw是奇数时 Pw为偶数 我们会在上下左右padding P/2</p>
<p> 当Kw是偶数时，Pw为奇数，我们会padding 向上取整P/2(这个情况非常少见)</p>
</blockquote>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>当我们输入的图像比较大，但是在深度学习中我们一般采用的卷积核是比较小的，我们就需要特别多的层才能把图像大小降下来，<br>大家知道层数越多计算就越复杂，我们不希望这样的情况发生</p>
<table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>这时候就要让卷积核迈大脚步了 o(&gt;ω&lt;)o</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p><img src="https://ai-studio-static-online.cdn.bcebos.com/943ec9d9834f4544985bdcb559df8038c65ea6ffa16f4138897b36ae741c3682"></p>
<blockquote>
<h1 id="步幅-Stride"><a href="#步幅-Stride" class="headerlink" title="步幅(Stride)"></a>步幅(Stride)</h1><p>卷积过程中，有时需要通过填充来避免信息损失，有时也要在卷积时通过设置的步长(Stride)来压缩一部分信息。因此卷积中的步幅是另一个构建卷积神经网络的基本操作。</p>
<p>例如下图</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/dd096c7f528f4e7eb0a11f3a4ff3c15e89f45cfdcc5644f0993d8b3f63ec698e"></p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>这里补充一下通过卷积后输出的大小的计算公式</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/b1367802c1fb4229952cc4336cfd648be9e440e9f3d24bac8ad0c06659145e41"></p>
<h1 id="多通道的输入和输出"><a href="#多通道的输入和输出" class="headerlink" title="多通道的输入和输出"></a>多通道的输入和输出</h1><p>我们都知道图片是彩色的，一般来说图片有RGB三个通道</p>
<p>下面有请今天的玩伴女郎 — Lena同学！！！ ๑乛◡乛๑</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/968bd9ee4ed6486f943133dcf18f4b5360d6c859747c474eb65259d46bf939da"></p>
<p>为了直观显示，我把单个通道的亮度分别调到255</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/ccba15e7632f4a97ace26141c3a0b79ee43bc23e4bac48f985d9052edd7eed5d"></p>
<p>然后我们把三个通道的图片输入到网络中。不过我们要如何处理呢？</p>
<h1 id="二维卷积"><a href="#二维卷积" class="headerlink" title="二维卷积"></a>二维卷积</h1><table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>我猜，刚刚一个输入用一个卷积核，现在有三个应该要用三个卷积核。(⊙ᗜ⊙)</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>没错，我们将每个通道的图片和一个卷积核卷积，三个通道就有三个卷积后的输出，然后我们将输出矩阵相加就可以得到一个输出。这样的方式我们可以叫他二维卷积</p>
<p>让我们来看下具体过程吧！(以输入通道为2为例)｡◕ᴗ◕｡</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/daf0b3cf82644e1d9a39f807a8de21500bbba30586c14b9bb8e62ecb92b9d7f3"></p>
<h1 id="三维卷积"><a href="#三维卷积" class="headerlink" title="三维卷积"></a>三维卷积</h1><table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>我懂了，三个卷积核可以有一个输出，如果我要多通道输出的话，我整多批的三个卷积核对输入图像卷积我就可以得到多个输出了！ᕙ( * •̀ ᗜ •́ * )ᕗ</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>没错，这就是多输出的方法，我们也可以叫做三维卷积，可以看一下过程｡◕ᴗ◕｡</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/3917ee42758f4306b36006a8a38c48c98607a95e98b04c62bea2ce4390a84dc5"></p>
<p>我们可以将每个通道看作是对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器。</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>眼尖的同学是不是有一个疑问，为什么我上面图片中用到了一个1x1的卷积核</p>
<p>哈哈，这又是一个知识点了o(￣▽￣)ｄ</p>
<blockquote>
<h1 id="1×1-卷积层"><a href="#1×1-卷积层" class="headerlink" title="1×1 卷积层"></a>1×1 卷积层</h1><p>先说我们为什么要引入一个1x1的卷积层，我们发现，这个卷积层并不会压缩大小，而是将三个通道的信息进行了整合变成了一个通道</p>
<p>因为使用了最小窗口，卷积失去了在高度和宽度维度上识别相邻元素间相互作用的能力，而是在通道上具有了能力我们可以将1x1卷积层看作是在每个像素位置应用了全连接层</p>
<p>因此1x1卷积层是一个受欢迎的选择</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/cd8e6e8cee2541debeb4e300a26135248d476eea8a714605b8ae7b1a7a7add1a"></p>
<blockquote>
<h1 id="第一阶段小结"><a href="#第一阶段小结" class="headerlink" title="第一阶段小结"></a>第一阶段小结</h1><p>1.卷积是对图像提取特征的操作</p>
<p>2.填充能减少边缘信息丢失</p>
<p>3.如果我们发现原始的输入分辨率十分冗余我们可以增大步幅</p>
<p>4.输出通道数是卷积层的超参数</p>
<p>5.二维卷积: 每个输入通道有独立的二维卷积核，所有通道结果相加得到一个输出通道结果</p>
<p>6.三维卷积: 每个输出通道有独立的三维卷积核</p>
</blockquote>
<blockquote>
<h1 id="汇聚层-池化层"><a href="#汇聚层-池化层" class="headerlink" title="汇聚层(池化层)"></a>汇聚层(池化层)</h1><p>由于卷积层对位置信息特别的敏感，可能因为物体位置不同导致卷积无法很好的处理。</p>
<p>这个时候就需要用到池化层</p>
<p>池化层能保持一定范围内的不变性，削弱卷积层对位置的过度敏感性。</p>
<p>池化有很多种  最大池化、平均池化、重叠池化、非重叠池化、金字塔池化SPP、双线性池化（Bilinear Pooling）</p>
<p>这里我主要讲最常用的最大池化和平均池化</p>
</blockquote>
<h1 id="最大池化-Max-Pooling"><a href="#最大池化-Max-Pooling" class="headerlink" title="最大池化(Max-Pooling)"></a>最大池化(Max-Pooling)</h1><p><img src="https://ai-studio-static-online.cdn.bcebos.com/d16e169b71b241d9b065cd61ac4ef3791f40b544bf824121a6baafdb0c5d5abb"></p>
<p>与卷积类似，最大池化也是以滑窗的方式进行，不过不同的是池化并没有用卷积核，而是算出跟窗口一样大的区域内的最大值。</p>
<p>池化和卷积一样也有填充和步幅</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>
让我们来看看池化是如何削弱卷积对位置信息的过度敏感

<p>对输入图像先用左边是1右边是-1的2x2卷积核进行卷积，再对输出结果做最大池化，我们会发现出现了一个像素的位移，使得卷积核对位置的敏感度降低</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/46556a0cb1ab4c3b8151d89cd8c00715e6dd283293de4c95af53aac33f9fe743"></p>
<h1 id="平均池化-Mean-Pooling"><a href="#平均池化-Mean-Pooling" class="headerlink" title="平均池化(Mean-Pooling)"></a>平均池化(Mean-Pooling)</h1><p>平均池化也是通过滑窗的方式，只不过将之前取最大的计算方式换成求平均</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/8cde5c74b9534ed083480131de93b3281f831d9568f2458ba5c21a2a81bb66e6"></p>
<table><tr><td bgcolor=orange>王小美:</td></tr></table>

<p>这两种不同的池化有啥区别吗ヾ（≧?≦）〃？？</p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>一般来说，mean-pooling能减小第一种误差，更多的保留图像的背景信息，max-pooling能减小第二种误差，更多的保留纹理信息。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/3405a39e15fd41fda2d5a338c744cfe6f4ac16bf5f624015a30101c1de74bb82"></p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>好了，基本概念就讲到这了。让我们进入卷积神经网络吧！ o(&gt;ω&lt;)o</p>
<h1 id="经典卷积神经网络-LeNet-卷积神经网络中的HelloWorld"><a href="#经典卷积神经网络-LeNet-卷积神经网络中的HelloWorld" class="headerlink" title="经典卷积神经网络 LeNet(卷积神经网络中的HelloWorld)"></a>经典卷积神经网络 LeNet(卷积神经网络中的HelloWorld)</h1><p><img src="https://ai-studio-static-online.cdn.bcebos.com/7b987f92c45747fab679cf2ce5cc5d1fcac53a578c7e4a189e9263bf731d6c10"></p>
<blockquote>
<p>这个模型是由AT&amp;T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像LeCun.Bottou.Bengio.ea.1998中的手写数字。 当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的研究，这项工作代表了十多年来神经网络研究开发的成果。</p>
<p>当时，LeNet取得了与支持向量机（SVM）性能相媲美的成果，成为监督学习的主流方法。 LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。 时至今日，一些自动取款机仍在运行Yann LeCun和他的同事Leon Bottou在上世纪90年代写的代码呢！</p>
</blockquote>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>通过这样图我们可以对Lenet网络的结构有很好的认识。接下来让我们通过paddle来复现一下Lenet吧！o(&gt;ω&lt;)o</p>
<p>回顾一下我们之前讲的<a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/5378450?contributionType=1&sUid=2413201&shared=1&ts=1673573678148">softmax实现图像分类任务</a></p>
<p>为了能够应用softmax回归，我们首先将每个大小为28×28的图像使用paddle.nn.Flatten展平为一个784维的固定长度的一维向量，然后用全连接层对其进行处理。<br>这样的做法会丢失很多空间信息，而现在，我们已经掌握了卷积层的处理方法，我们可以在图像中保留空间结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn, optimizer</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2D(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    <span class="comment"># 一个输入6个输出 padding=2可以把28x28补到32x32，使用了sigmoid激活函数使其具有非线性性，</span></span><br><span class="line">    <span class="comment"># 关于激活函数的介绍我们下节课再讲，除了sigmoid你还可以是试试relu、tanh，relu是我们当今最常用的</span></span><br><span class="line">    nn.AvgPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2D(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    <span class="comment"># 由于后面要接全连接层所以这边将他摊平</span></span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由于Lenet后面接的高斯层我们当今已经不再使用了，所以这里就将其去除了。除此之外该网络与上图一致</span></span><br></pre></td></tr></table></figure>

<pre><code>W0113 17:24:16.045086   180 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0113 17:24:16.049470   180 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 让我们来看一下网络情况</span></span><br><span class="line">paddle.summary(net,(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br></pre></td></tr></table></figure>

<pre><code>---------------------------------------------------------------------------
 Layer (type)       Input Shape          Output Shape         Param #    
===========================================================================
   Conv2D-1       [[1, 1, 28, 28]]      [1, 6, 28, 28]          156      
   Sigmoid-1      [[1, 6, 28, 28]]      [1, 6, 28, 28]           0       
  AvgPool2D-1     [[1, 6, 28, 28]]      [1, 6, 14, 14]           0       
   Conv2D-2       [[1, 6, 14, 14]]     [1, 16, 10, 10]         2,416     
   Sigmoid-2     [[1, 16, 10, 10]]     [1, 16, 10, 10]           0       
  AvgPool2D-2    [[1, 16, 10, 10]]      [1, 16, 5, 5]            0       
   Flatten-1      [[1, 16, 5, 5]]          [1, 400]              0       
   Linear-1          [[1, 400]]            [1, 120]           48,120     
   Sigmoid-3         [[1, 120]]            [1, 120]              0       
   Linear-2          [[1, 120]]            [1, 84]            10,164     
   Sigmoid-4         [[1, 84]]             [1, 84]               0       
   Linear-3          [[1, 84]]             [1, 10]              850      
===========================================================================
Total params: 61,706
Trainable params: 61,706
Non-trainable params: 0
---------------------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.11
Params size (MB): 0.24
Estimated Total Size (MB): 0.35
---------------------------------------------------------------------------






&#123;&#39;total_params&#39;: 61706, &#39;trainable_params&#39;: 61706&#125;
</code></pre>
<p>但是Sequential(循序容器)顾名思义，只能搭建循序执行的网络，一些跳跃连接的网络无法执行 ，所以可以用class创建一个类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Layer):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    继承paddle.nn.Layer定义网络结构</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">10</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化函数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),  <span class="comment"># 第一层卷积</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># 激活函数</span></span><br><span class="line">            nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),  <span class="comment"># 最大池化，下采样</span></span><br><span class="line">            nn.Conv2D(in_channels=<span class="number">6</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>), <span class="comment"># 第二层卷积</span></span><br><span class="line">            nn.Sigmoid(), <span class="comment"># 激活函数</span></span><br><span class="line">            nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>) <span class="comment"># 最大池化，下采样</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">400</span>, <span class="number">120</span>),  <span class="comment"># 全连接</span></span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>),   <span class="comment"># 全连接</span></span><br><span class="line">            nn.Linear(<span class="number">84</span>, num_classes) <span class="comment"># 输出层</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向计算</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        y = self.features(inputs)</span><br><span class="line">        y = paddle.flatten(y, <span class="number">1</span>)</span><br><span class="line">        out = self.fc(y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">network_2 = LeNet()</span><br><span class="line">paddle.summary(network_2,(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br></pre></td></tr></table></figure>

<pre><code>---------------------------------------------------------------------------
 Layer (type)       Input Shape          Output Shape         Param #    
===========================================================================
   Conv2D-3       [[1, 1, 28, 28]]      [1, 6, 28, 28]          60       
   Sigmoid-5      [[1, 6, 28, 28]]      [1, 6, 28, 28]           0       
  MaxPool2D-1     [[1, 6, 28, 28]]      [1, 6, 14, 14]           0       
   Conv2D-4       [[1, 6, 14, 14]]     [1, 16, 10, 10]         2,416     
   Sigmoid-6     [[1, 16, 10, 10]]     [1, 16, 10, 10]           0       
  MaxPool2D-2    [[1, 16, 10, 10]]      [1, 16, 5, 5]            0       
   Linear-4          [[1, 400]]            [1, 120]           48,120     
   Linear-5          [[1, 120]]            [1, 84]            10,164     
   Linear-6          [[1, 84]]             [1, 10]              850      
===========================================================================
Total params: 61,610
Trainable params: 61,610
Non-trainable params: 0
---------------------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.11
Params size (MB): 0.24
Estimated Total Size (MB): 0.35
---------------------------------------------------------------------------






&#123;&#39;total_params&#39;: 61610, &#39;trainable_params&#39;: 61610&#125;
</code></pre>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>让我们来试试模型的效果吧！</p>
<p>还记得我们的步骤吗？</p>
<h1 id="1-数据处理"><a href="#1-数据处理" class="headerlink" title="1.数据处理"></a>1.数据处理</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过paddle2.0的数据集读取api读取数据</span></span><br><span class="line"><span class="keyword">import</span> paddle.vision.transforms <span class="keyword">as</span> T</span><br><span class="line">transform = T.Normalize(mean=[<span class="number">127.5</span>], std=[<span class="number">127.5</span>]) <span class="comment"># 将数据归一化到[-1, 1]，参考原论文</span></span><br><span class="line">train_dataset = paddle.vision.datasets.MNIST(mode=<span class="string">&#x27;train&#x27;</span>, transform=transform)</span><br><span class="line">val_dataset =  paddle.vision.datasets.MNIST(mode=<span class="string">&#x27;test&#x27;</span>, transform=transform)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集有&#123;&#125;\n测试集有&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(train_dataset),<span class="built_in">len</span>(val_dataset)))</span><br></pre></td></tr></table></figure>

<pre><code>item    8/2421 [..............................] - ETA: 8s - 4ms/item

Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz 
Begin to download


item 8/8 [============================&gt;.] - ETA: 0s - 5ms/item


Download finished
Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz 
Begin to download

Download finished


item  12/403 [..............................] - ETA: 2s - 7ms/item

Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz 
Begin to download


item 2/2 [===========================&gt;..] - ETA: 0s - 3ms/item


Download finished
Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz 
Begin to download

Download finished


训练集有60000
测试集有10000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用matplotlib库绘制图像</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;图片：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(train_dataset[<span class="number">0</span>][<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(train_dataset[<span class="number">0</span>][<span class="number">0</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Label：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(train_dataset[<span class="number">0</span>][<span class="number">1</span>]))</span><br><span class="line"><span class="built_in">print</span>(train_dataset[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化展示</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(train_dataset[<span class="number">0</span>][<span class="number">0</span>].reshape([<span class="number">28</span>,<span class="number">28</span>]), cmap=plt.cm.binary)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>图片：
&lt;class &#39;numpy.ndarray&#39;&gt;
(1, 28, 28)
Label：
&lt;class &#39;numpy.ndarray&#39;&gt;
[5]


/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/image.py:425: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead
  a_min = np.asscalar(a_min.astype(scaled_dtype))
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/image.py:426: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead
  a_max = np.asscalar(a_max.astype(scaled_dtype))
</code></pre>
<p><img src="main_files/main_44_2.png" alt="png"></p>
<table><tr><td bgcolor=baby blue>三岁:</td></tr></table>

<p>还记得我们之前说的通过paddle api进行训练吗？ ٩(◕‿◕｡)۶</p>
<p>忘了的请务必再看一次，没点赞的话记得点个赞哈哈 </p>
<p><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/5378450?contributionType=1&sUid=2413201&shared=1&ts=1673582246540">不记得的话再看一次吧！点击跳转</a></p>
<h1 id="2-组网"><a href="#2-组网" class="headerlink" title="2.组网"></a>2.组网</h1><p>这里因为前面已经组好了所以直接跳下一步</p>
<h1 id="3-训练和调参"><a href="#3-训练和调参" class="headerlink" title="3.训练和调参"></a>3.训练和调参</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = paddle.Model(network_2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型配置</span></span><br><span class="line">model.prepare(paddle.optimizer.Adam(learning_rate=<span class="number">0.001</span>, parameters=model.parameters()), <span class="comment"># Adam优化器</span></span><br><span class="line">              paddle.nn.CrossEntropyLoss(), <span class="comment"># 损失函数 交叉熵</span></span><br><span class="line">              paddle.metric.Accuracy()) <span class="comment"># 评估指标</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动全流程训练</span></span><br><span class="line">model.fit(train_dataset,  <span class="comment"># 训练数据集</span></span><br><span class="line">          val_dataset,   <span class="comment"># 评估数据集</span></span><br><span class="line">          epochs=<span class="number">5</span>,       <span class="comment"># 训练轮次</span></span><br><span class="line">          batch_size=<span class="number">64</span>,  <span class="comment"># 单次计算数据样本量</span></span><br><span class="line">          verbose=<span class="number">1</span>)      <span class="comment"># 日志展示形式，进度条</span></span><br></pre></td></tr></table></figure>

<pre><code>The loss value printed in the log is the current step, and the metric is the average value of previous steps.
Epoch 1/5
step 938/938 [==============================] - loss: 0.1858 - acc: 0.8464 - 10ms/step          
Eval begin...
step 157/157 [==============================] - loss: 0.0200 - acc: 0.9503 - 8ms/step          
Eval samples: 10000
Epoch 2/5
step 938/938 [==============================] - loss: 0.0871 - acc: 0.9550 - 10ms/step          
Eval begin...
step 157/157 [==============================] - loss: 0.0068 - acc: 0.9703 - 8ms/step          
Eval samples: 10000
Epoch 3/5
step 938/938 [==============================] - loss: 0.0128 - acc: 0.9667 - 10ms/step          
Eval begin...
step 157/157 [==============================] - loss: 0.0036 - acc: 0.9717 - 8ms/step          
Eval samples: 10000
Epoch 4/5
step 938/938 [==============================] - loss: 0.0079 - acc: 0.9720 - 10ms/step          
Eval begin...
step 157/157 [==============================] - loss: 0.0026 - acc: 0.9774 - 8ms/step          
Eval samples: 10000
Epoch 5/5
step 938/938 [==============================] - loss: 0.1188 - acc: 0.9763 - 9ms/step          
Eval begin...
step 157/157 [==============================] - loss: 4.6758e-04 - acc: 0.9826 - 8ms/step      
Eval samples: 10000
</code></pre>
<h1 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用测试集进行测试</span></span><br><span class="line">model.evaluate(val_dataset, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Eval begin...
step 10000/10000 [==============================] - loss: 3.5763e-07 - acc: 0.9826 - 2ms/step          
Eval samples: 10000





&#123;&#39;loss&#39;: [3.576278e-07], &#39;acc&#39;: 0.9826&#125;
</code></pre>
<blockquote>
<h1 id="Model-predict"><a href="#Model-predict" class="headerlink" title="Model.predict"></a>Model.predict</h1><p>高层 API 中提供了 Model.predict 接口，可对训练好的模型进行推理验证。只需传入待执行推理验证的样本数据，即可计算并返回推理结果。</p>
<p>返回格式是一个列表：</p>
<p>模型是单一输出：[(numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n)]</p>
<p>模型是多输出：[(numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n), (numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n), …]</p>
<p>如果模型是单一输出，则输出的形状为 [1, n]，n 表示数据集的样本数。其中每个 numpy_ndarray_n 是对应原始数据经过模型计算后得到的预测结果，类型为 numpy 数组，例如 mnist 分类任务中，每个 numpy_ndarray_n 是长度为 10 的 numpy 数组。</p>
<p>如果模型是多输出，则输出的形状为[m, n]，m 表示标签的种类数，在多标签分类任务中，m 会根据标签的数目而定。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 批量预测测试集</span></span><br><span class="line">result = model.predict(val_dataset)</span><br></pre></td></tr></table></figure>

<pre><code>Predict begin...
step 10000/10000 [==============================] - 2ms/step          
Predict samples: 10000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义画图方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_img</span>(<span class="params">img, predict</span>):</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.title(<span class="string">&#x27;predict: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(predict))</span><br><span class="line">    plt.imshow(img.reshape([<span class="number">28</span>, <span class="number">28</span>]), cmap=plt.cm.binary)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 抽样展示</span></span><br><span class="line">indexs = [<span class="number">2</span>, <span class="number">66</span>, <span class="number">33</span>, <span class="number">222</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> indexs:</span><br><span class="line">    show_img(val_dataset[idx][<span class="number">0</span>], np.argmax(result[<span class="number">0</span>][idx]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># np.argmax是用于取得数组中每一行或者每一列的的最大值</span></span><br></pre></td></tr></table></figure>


<p><img src="main_files/main_53_0.png" alt="png"></p>
<p><img src="main_files/main_53_1.png" alt="png"></p>
<p><img src="main_files/main_53_2.png" alt="png"></p>
<p><img src="main_files/main_53_3.png" alt="png"></p>
<h1 id="4-模型保存与加载"><a href="#4-模型保存与加载" class="headerlink" title="4.模型保存与加载"></a>4.模型保存与加载</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">&#x27;model/mnist&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载动态图模型参数和优化器参数</span></span><br><span class="line">model.load(<span class="string">&#x27;/home/aistudio/model/mnist&#x27;</span>)</span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">2</span>, batch_size=<span class="number">64</span>, save_freq=<span class="number">1</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过它的参数 save_freq可以设置保存动态图模型的频率，即多少个 epoch 保存一次模型，默认值是 1。</span></span><br></pre></td></tr></table></figure>

<pre><code>The loss value printed in the log is the current step, and the metric is the average value of previous steps.
Epoch 1/2
step 938/938 [==============================] - loss: 0.0201 - acc: 0.9788 - 10ms/step          
Epoch 2/2
step 938/938 [==============================] - loss: 0.0183 - acc: 0.9808 - 9ms/step          
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用测试集进行测试</span></span><br><span class="line">model.evaluate(val_dataset, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Eval begin...
step 10000/10000 [==============================] - loss: 5.9605e-07 - acc: 0.9840 - 2ms/step          
Eval samples: 10000





&#123;&#39;loss&#39;: [5.960463e-07], &#39;acc&#39;: 0.984&#125;
</code></pre>
<h1 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h1><p>ID：Flose</p>
<p>School：浙大宁波理工学院</p>
<p>专业：自动化</p>
<p>宁理炼丹师协会-飞桨领航团QQ群：699816720</p>
<p>深度学习菜狗，正在不断努力，咱们一起加油</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://flose.cn">Flose</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://flose.cn/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">https://flose.cn/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://flose.cn" target="_blank">Flose's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/cs/">cs</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="https://ai-studio-static-online.cdn.bcebos.com/c40042ec75d5412da45370abe110559a5fc38c887cb24b2f9010409f4523d918" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/02/27/%E5%85%AC%E5%8F%B8%E4%BB%8B%E7%BB%8D_TI/" title="宇宙第一模拟半导体元件的制造商TI？"><img class="cover" src="https://i.328888.xyz/2023/02/27/e3PIz.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">宇宙第一模拟半导体元件的制造商TI？</div></div></a></div><div class="next-post pull-right"><a href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" title="跟着王小美和三岁一起学paddle(3)--图像分类"><img class="cover" src="https://ai-studio-static-online.cdn.bcebos.com/46ed8e93aeca4a059ed14cd72090cf4711f398e634c0400c8a14fef8f42967cd" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">跟着王小美和三岁一起学paddle(3)--图像分类</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" title="跟着王小美和三岁一起学paddle(3)--图像分类"><img class="cover" src="https://ai-studio-static-online.cdn.bcebos.com/46ed8e93aeca4a059ed14cd72090cf4711f398e634c0400c8a14fef8f42967cd" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-26</div><div class="title">跟着王小美和三岁一起学paddle(3)--图像分类</div></div></a></div><div><a href="/2023/02/26/%E8%B7%9F%E7%9D%80%E7%8E%8B%E5%B0%8F%E7%BE%8E%E5%92%8C%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle--Tensor%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/" title="跟着王小美和三岁一起学paddle--Tensor是什么？"><img class="cover" src="https://ai-studio-static-online.cdn.bcebos.com/9ae3002c51794d17b9003e8337e3d4dc244339c89e524c01bb64176df1d0659a" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-26</div><div class="title">跟着王小美和三岁一起学paddle--Tensor是什么？</div></div></a></div><div><a href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E7%8E%8B%E5%B0%8F%E7%BE%8E%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%A8%8B%E5%BA%8F/" title="跟着王小美和三岁一起学paddle(2)--第一个机器学习程序"><img class="cover" src="https://ai-studio-static-online.cdn.bcebos.com/30da901ef6ac4ce68ca9b269af8c1cb0d3bc9c2880054e0ab0f23f161eeaeab8" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-26</div><div class="title">跟着王小美和三岁一起学paddle(2)--第一个机器学习程序</div></div></a></div><div><a href="/2023/02/26/cs%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/" title="cs学习指南"><img class="cover" src="http://up.36992.com/pic/e6/c5/51/e6c551e768092c8655292d89a4034a74.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-26</div><div class="title">cs学习指南</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.328888.xyz/2023/02/26/ESj8a.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Flose</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/2413201"><i class="fa fa-address-card"></i><span>My Aistudio</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/coinlockerbaby" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:seeyounextsun@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://jq.qq.com/?_wv=1027&amp;k=f0XSK9yv" target="_blank" title="QQ交流群"><i class="fa fa-commenting"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle-%E2%80%94-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AF%87%EF%BC%81"><span class="toc-number">1.</span> <span class="toc-text">跟王小美与三岁一起学paddle — 卷积神经网络篇！</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-number">2.</span> <span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">3.</span> <span class="toc-text">卷积层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A1%AB%E5%85%85-padding"><span class="toc-number">4.</span> <span class="toc-text">填充(padding)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%AD%A5%E5%B9%85-Stride"><span class="toc-number">5.</span> <span class="toc-text">步幅(Stride)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E9%80%9A%E9%81%93%E7%9A%84%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA"><span class="toc-number">6.</span> <span class="toc-text">多通道的输入和输出</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF"><span class="toc-number">7.</span> <span class="toc-text">二维卷积</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E7%BB%B4%E5%8D%B7%E7%A7%AF"><span class="toc-number">8.</span> <span class="toc-text">三维卷积</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1%C3%971-%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">9.</span> <span class="toc-text">1×1 卷积层</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93"><span class="toc-number">10.</span> <span class="toc-text">第一阶段小结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B1%87%E8%81%9A%E5%B1%82-%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="toc-number">11.</span> <span class="toc-text">汇聚层(池化层)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96-Max-Pooling"><span class="toc-number">12.</span> <span class="toc-text">最大池化(Max-Pooling)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B9%B3%E5%9D%87%E6%B1%A0%E5%8C%96-Mean-Pooling"><span class="toc-number">13.</span> <span class="toc-text">平均池化(Mean-Pooling)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-LeNet-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84HelloWorld"><span class="toc-number">14.</span> <span class="toc-text">经典卷积神经网络 LeNet(卷积神经网络中的HelloWorld)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">15.</span> <span class="toc-text">1.数据处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E7%BB%84%E7%BD%91"><span class="toc-number">16.</span> <span class="toc-text">2.组网</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E8%AE%AD%E7%BB%83%E5%92%8C%E8%B0%83%E5%8F%82"><span class="toc-number">17.</span> <span class="toc-text">3.训练和调参</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81"><span class="toc-number">18.</span> <span class="toc-text">模型验证</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Model-predict"><span class="toc-number">19.</span> <span class="toc-text">Model.predict</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"><span class="toc-number">20.</span> <span class="toc-text">4.模型保存与加载</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E8%80%85%E7%AE%80%E4%BB%8B"><span class="toc-number">21.</span> <span class="toc-text">作者简介</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/02/27/%E5%85%AC%E5%8F%B8%E4%BB%8B%E7%BB%8D_TI/" title="宇宙第一模拟半导体元件的制造商TI？"><img src="https://i.328888.xyz/2023/02/27/e3PIz.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="宇宙第一模拟半导体元件的制造商TI？"/></a><div class="content"><a class="title" href="/2023/02/27/%E5%85%AC%E5%8F%B8%E4%BB%8B%E7%BB%8D_TI/" title="宇宙第一模拟半导体元件的制造商TI？">宇宙第一模拟半导体元件的制造商TI？</a><time datetime="2023-02-27T10:14:01.000Z" title="发表于 2023-02-27 18:14:01">2023-02-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="跟着王小美和三岁一起学paddle(4)--卷积神经网络"><img src="https://ai-studio-static-online.cdn.bcebos.com/c40042ec75d5412da45370abe110559a5fc38c887cb24b2f9010409f4523d918" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="跟着王小美和三岁一起学paddle(4)--卷积神经网络"/></a><div class="content"><a class="title" href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="跟着王小美和三岁一起学paddle(4)--卷积神经网络">跟着王小美和三岁一起学paddle(4)--卷积神经网络</a><time datetime="2023-02-26T12:54:01.000Z" title="发表于 2023-02-26 20:54:01">2023-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" title="跟着王小美和三岁一起学paddle(3)--图像分类"><img src="https://ai-studio-static-online.cdn.bcebos.com/46ed8e93aeca4a059ed14cd72090cf4711f398e634c0400c8a14fef8f42967cd" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="跟着王小美和三岁一起学paddle(3)--图像分类"/></a><div class="content"><a class="title" href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" title="跟着王小美和三岁一起学paddle(3)--图像分类">跟着王小美和三岁一起学paddle(3)--图像分类</a><time datetime="2023-02-26T12:54:01.000Z" title="发表于 2023-02-26 20:54:01">2023-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/26/%E8%B7%9F%E7%9D%80%E7%8E%8B%E5%B0%8F%E7%BE%8E%E5%92%8C%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle--Tensor%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/" title="跟着王小美和三岁一起学paddle--Tensor是什么？"><img src="https://ai-studio-static-online.cdn.bcebos.com/9ae3002c51794d17b9003e8337e3d4dc244339c89e524c01bb64176df1d0659a" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="跟着王小美和三岁一起学paddle--Tensor是什么？"/></a><div class="content"><a class="title" href="/2023/02/26/%E8%B7%9F%E7%9D%80%E7%8E%8B%E5%B0%8F%E7%BE%8E%E5%92%8C%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle--Tensor%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/" title="跟着王小美和三岁一起学paddle--Tensor是什么？">跟着王小美和三岁一起学paddle--Tensor是什么？</a><time datetime="2023-02-26T12:54:01.000Z" title="发表于 2023-02-26 20:54:01">2023-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E7%8E%8B%E5%B0%8F%E7%BE%8E%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%A8%8B%E5%BA%8F/" title="跟着王小美和三岁一起学paddle(2)--第一个机器学习程序"><img src="https://ai-studio-static-online.cdn.bcebos.com/30da901ef6ac4ce68ca9b269af8c1cb0d3bc9c2880054e0ab0f23f161eeaeab8" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="跟着王小美和三岁一起学paddle(2)--第一个机器学习程序"/></a><div class="content"><a class="title" href="/2023/02/26/%E8%B7%9F%E7%8E%8B%E5%B0%8F%E7%BE%8E%E4%B8%8E%E4%B8%89%E5%B2%81%E4%B8%80%E8%B5%B7%E5%AD%A6paddle%20%E2%80%94%20%E7%8E%8B%E5%B0%8F%E7%BE%8E%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%A8%8B%E5%BA%8F/" title="跟着王小美和三岁一起学paddle(2)--第一个机器学习程序">跟着王小美和三岁一起学paddle(2)--第一个机器学习程序</a><time datetime="2023-02-26T12:54:01.000Z" title="发表于 2023-02-26 20:54:01">2023-02-26</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Flose</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'CBh3CVLEPggVfEKai0Vsb3wj-9Nh9j0Va',
      appKey: '7IbFlM3DJ0Cc1ICEjG3wkxAk',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      master: '6a5cf78d405eeadc3b6d9bb6d1136d89',   //博主邮箱md5加密32位小写
      tagMeta: ["博主","小伙伴","访客"],     //标识字段名
      friends:  [],  //小伙伴邮箱Md5
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('/js/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script src="/js/font.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></body></html>